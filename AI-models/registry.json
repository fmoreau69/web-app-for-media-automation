{
  "models": {
    "llama3.2": {
      "id": "llama3.2",
      "name": "Llama 3.2",
      "category": "language-model",
      "source": "ollama",
      "managed_by": "ollama",
      "ollama_model_name": "llama3.2:latest",
      "downloaded": true,
      "local_path": "~/.ollama/models",
      "size_gb": 4.7,
      "format": "gguf",
      "license": "Llama 3.2",
      "compatible_apps": [
        "describer",
        "chatbot"
      ],
      "capabilities": {
        "context_length": 128000,
        "multimodal": false,
        "tasks": [
          "text-generation",
          "chat",
          "code"
        ]
      },
      "ollama_info": {
        "version": "latest",
        "quantization": "Q4_K_M",
        "parameter_count": "3B"
      }
    },
    "llava:13b": {
      "id": "llava-13b",
      "name": "LLaVA 13B",
      "category": "vision-language-model",
      "source": "ollama",
      "managed_by": "ollama",
      "ollama_model_name": "llava:13b",
      "downloaded": false,
      "size_gb": 8.0,
      "compatible_apps": [
        "describer"
      ],
      "capabilities": {
        "multimodal": true,
        "vision": true,
        "tasks": [
          "image-to-text",
          "visual-question-answering"
        ]
      },
      "whisper-large-v3": {
        "id": "whisper-large-v3",
        "name": "Whisper Large V3",
        "category": "speech-to-text",
        "source": "huggingface",
        "repo": "openai/whisper-large-v3",
        "downloaded": true,
        "local_path": "AI-models/downloaded/whisper-large-v3",
        "size_gb": 3.1,
        "format": "pytorch",
        "license": "MIT",
        "last_updated": "2025-01-15",
        "capabilities": {
          "tasks": [
            "transcription",
            "translation"
          ],
          "languages": [
            "en",
            "fr",
            "es",
            "de",
            "..."
          ],
          "max_audio_length": 30
        },
        "compatible_apps": [
          "transcriber"
        ],
        "performance": {
          "wer": 0.08,
          "speed": "medium",
          "gpu_memory_gb": 5
        }
      },
      "yolov8n": {
        "id": "yolov8n",
        "name": "YOLOv8 Nano",
        "category": "object-detection",
        "source": "github",
        "url": "https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt",
        "downloaded": true,
        "local_path": "AI-models/downloaded/yolov8n.pt",
        "size_gb": 0.006,
        "format": "pytorch",
        "license": "AGPL-3.0",
        "capabilities": {
          "tasks": [
            "detection",
            "segmentation"
          ],
          "classes": 80,
          "input_size": [
            640,
            640
          ]
        },
        "compatible_apps": [
          "detector",
          "anonymizer"
        ],
        "performance": {
          "map50": 0.527,
          "fps": 140,
          "gpu_memory_gb": 0.5
        }
      },
      "sd-xl-base-1.0": {
        "id": "sd-xl-base-1.0",
        "name": "Stable Diffusion XL Base 1.0",
        "category": "text-to-image",
        "source": "huggingface",
        "repo": "stabilityai/stable-diffusion-xl-base-1.0",
        "downloaded": false,
        "size_gb": 6.9,
        "format": "diffusers",
        "compatible_apps": [
          "imager",
          "enhancer"
        ],
        "variants": {
          "base": "stable-diffusion-xl-base-1.0",
          "refiner": "stable-diffusion-xl-refiner-1.0",
          "inpaint": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1"
        }
      },
      "bark": {
        "id": "bark",
        "name": "Bark TTS",
        "category": "text-to-speech",
        "source": "huggingface",
        "repo": "suno/bark",
        "downloaded": true,
        "local_path": "AI-models/downloaded/bark",
        "compatible_apps": [
          "synthesizer"
        ],
        "capabilities": {
          "languages": [
            "en",
            "fr",
            "de",
            "es",
            "it",
            "pt",
            "pl",
            "tr",
            "ru",
            "nl",
            "cs",
            "ar",
            "zh",
            "ja",
            "hu",
            "ko"
          ],
          "voice_cloning": true,
          "multilingual": true
        }
      },
      "sam-vit-h": {
        "id": "sam-vit-h",
        "name": "Segment Anything Model (ViT-H)",
        "category": "segmentation",
        "source": "github",
        "url": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth",
        "downloaded": true,
        "local_path": "AI-models/downloaded/sam-vit-h.pth",
        "size_gb": 2.4,
        "compatible_apps": [
          "detector",
          "anonymizer",
          "enhancer"
        ]
      }
    },
    "app_models_mapping": {
      "anonymizer": {
        "face_detection": [
          "yolov8-face",
          "retinaface"
        ],
        "body_detection": [
          "yolov8n",
          "detectron2"
        ],
        "text_detection": [
          "easyocr",
          "paddleocr"
        ],
        "segmentation": [
          "sam-vit-h",
          "sam-vit-l"
        ],
        "inpainting": [
          "sd-xl-inpaint",
          "lama-inpainting"
        ]
      },
      "detector": {
        "object_detection": [
          "yolov8n",
          "yolov8s",
          "yolov8m",
          "detectron2"
        ],
        "segmentation": [
          "sam-vit-h",
          "yolov8-seg"
        ]
      },
      "transcriber": {
        "speech_to_text": [
          "whisper-large-v3",
          "whisper-medium",
          "wav2vec2"
        ]
      },
      "synthesizer": {
        "text_to_speech": [
          "bark",
          "coqui-tts",
          "styletts2"
        ]
      },
      "imager": {
        "text_to_image": [
          "sd-xl-base-1.0",
          "flux-dev",
          "dalle-mini"
        ]
      },
      "describer": {
        "image_to_text": [
          "blip2",
          "git-large",
          "llava"
        ]
      },
      "enhancer": {
        "super_resolution": [
          "realesrgan",
          "swinir"
        ],
        "denoising": [
          "nafnet",
          "restormer"
        ],
        "video_enhancement": [
          "basicvsr++"
        ]
      }
    }
  }
}